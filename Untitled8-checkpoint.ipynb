{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#manipulation and visualization libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import os\n",
    "\n",
    "#GIS Libraries\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the data\n",
    "CRIME = pd.read_csv(r\"./Police_Department_Incidents_-_Previous_Year__2016_.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (CRIME.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop NA and duplicate values\n",
    "CRIME.dropna(inplace = True)\n",
    "CRIME.drop_duplicates(inplace = True)\n",
    "CRIME.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete rows with NA\n",
    "CRIME = CRIME.dropna()\n",
    "\n",
    "CRIME['Date'] = pd.to_datetime(CRIME['Date'])\n",
    "\n",
    "CRIME['Time'] = pd.to_datetime(CRIME['Time'])\n",
    "\n",
    "CRIME['Hour'] = CRIME['Time'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Columns :',CRIME.columns)\n",
    "print('Indexes :',CRIME.index)\n",
    "\n",
    "print('Column types :',CRIME.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the different categories\n",
    "print('Categories :',CRIME.Category.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot unique values of selected features\n",
    "pd.value_counts(CRIME['Category']).plot(kind=\"bar\", figsize = (20, 8))\n",
    "plt.show()\n",
    "print(CRIME['Category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the different categories\n",
    "print('Descript :',CRIME.Descript.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Group dataset by crime occurences and time\n",
    "\n",
    "# crime_per_time = pd.to_datetime(df['Dates'], format=\"%Y-%m-%d %H:%M:%S\").dt.hour.value_counts().sort_index()\n",
    "crime_per_time = CRIME[\"Hour\"].value_counts().sort_index()\n",
    "crime_per_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to find the count of unique items in a specified column\n",
    "def unique_count(col_name):\n",
    "    unique, counts = np.unique(col_name, return_counts=True)\n",
    "    return dict(zip(unique, counts))\n",
    "\n",
    "#get districts in order to make the department key the same across graphs\n",
    "district_list = CRIME.PdDistrict.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get count for crimes per day of the week\n",
    "unique_count(CRIME.DayOfWeek)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#force the order of days in a graph\n",
    "days = ['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday']\n",
    "\n",
    "#graph day of the week values\n",
    "ax = sns.countplot(x=\"DayOfWeek\",\n",
    "                   hue = 'PdDistrict',\n",
    "                   data=CRIME,\n",
    "                   order=days,\n",
    "                  hue_order=district_list)\n",
    "\n",
    "plt.title('Crime by Day of the Week')\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross tabulation of DayOfWeek and Category columns\n",
    "cross_days_and_cat = pd.crosstab(index=CRIME['DayOfWeek'], columns=CRIME['Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot of 10 most committed crimes, each with the days of the week.\n",
    "cross_days_and_cat.loc[:,cross_days_and_cat.sum(axis=0).nlargest(10).index].plot.barh(subplots=True, sharey=True,\n",
    "                                                        sharex=False, layout=(5,2), figsize=(12,18), legend=False)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross tabulation of PdDistrict and Category columns\n",
    "cross_pd_and_cat = pd.crosstab(index=CRIME['PdDistrict'], columns=CRIME['Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Plot of PdDistrict and Crime\n",
    "cross_pd_and_cat.loc[:,cross_days_and_cat.sum(axis=0).nlargest(10).index].plot.barh(subplots=True, sharey=True,\n",
    "                                                        sharex=False, layout=(5,2), figsize=(12,18), legend=False)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross tabulation of hour and Category columns\n",
    "cross_pd_and_cat = pd.crosstab(index=CRIME['Hour'], columns=CRIME['Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Plot of 10 most committed crimes, each hour.\n",
    "cross_pd_and_cat.loc[:,cross_days_and_cat.sum(axis=0).nlargest(10).index].plot.barh(subplots=True, sharey=True,\n",
    "                                                        sharex=False, layout=(5,2), figsize=(16,22), legend=False)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.title('SF Crime Distribution')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.scatter(CRIME.X, CRIME.Y, s = 0.5, c = 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "marker_style = dict(color='red', linestyle=':', marker='D',\n",
    "                    markersize=5)\n",
    "\n",
    "\n",
    "CRIME = pd.read_csv(r\"./Police_Department_Incidents_-_Previous_Year__2016_.csv\")\n",
    "sns.lmplot('X', 'Y', data=CRIME, hue='PdDistrict', fit_reg=False)\n",
    "plt.ylabel('Latitude')\n",
    "plt.xlabel('Longitude')\n",
    "plt.title('San Francisco incidents 2016 colored by district')\n",
    "\n",
    "# place marker at the city center\n",
    "plt.plot(-122.419416, 37.774929, **marker_style)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goal: Create a Choropleth map to visualize crime in San Francisco.\n",
    "import pandas as pd\n",
    "import folium\n",
    "\n",
    "police_file = (r\"./Police_Department_Incidents_-_Previous_Year__2016_.csv\")\n",
    "sf_input = pd.read_csv(police_file, index_col=0)\n",
    "\n",
    "# group by neighborhood\n",
    "sf = sf_input.groupby('PdDistrict').count()\n",
    "sf = pd.DataFrame(sf,columns=['Category'])  # remove unneeded columns\n",
    "sf.reset_index(inplace=True)   # default index, otherwise groupby column becomes index\n",
    "sf.rename(columns={'PdDistrict':'Neighborhood','Category':'Count'}, inplace=True)\n",
    "sf.sort_values(by='Count', inplace=True, ascending=False)\n",
    "\n",
    "# San Francisco latitude and longitude values\n",
    "latitude = 37.7749\n",
    "longitude = -122.4194\n",
    "sf_neighborhood_geo = r'./san-francisco.geojson'\n",
    "\n",
    "# Create map\n",
    "sf_map = folium.Map(\n",
    "       location=[latitude,longitude],\n",
    "       zoom_start=12)\n",
    "\n",
    "# Use json file  TEST based on class\n",
    "sf_map.choropleth(\n",
    "       geo_data=sf_neighborhood_geo,\n",
    "       data=sf,\n",
    "       columns=['Neighborhood','Count'],\n",
    "       key_on='feature.properties.DISTRICT',\n",
    "       fill_color='YlOrRd',\n",
    "       fill_opacity='0.7',\n",
    "       line_opacity='0.2',\n",
    "       legend_name='Crime Rate in San Francisco, by Neighborhood')\n",
    "\n",
    "# display the map\n",
    "sf_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop all items with locations outside of San Francisco (latitude above 38)\n",
    "CRIME = CRIME[CRIME.Y < 38]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.title('SF Crime Distribution')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.scatter(CRIME.X, CRIME.Y, s = 0.5, c = 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the data\n",
    "CRIME = pd.read_csv(r\"./Police_Department_Incidents_-_Previous_Year__2016_.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop NA and duplicate values\n",
    "CRIME.dropna(inplace = True)\n",
    "CRIME.drop_duplicates(inplace = True)\n",
    "CRIME.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete rows with NA\n",
    "CRIME = CRIME.dropna()\n",
    "\n",
    "CRIME['Date'] = pd.to_datetime(CRIME['Date'])\n",
    "\n",
    "CRIME['Time'] = pd.to_datetime(CRIME['Time'])\n",
    "\n",
    "CRIME['Hour'] = CRIME['Time'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Columns :',CRIME.columns)\n",
    "print('Indexes :',CRIME.index)\n",
    "\n",
    "print('Column types :',CRIME.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop all items with locations outside of San Francisco (latitude above 38)\n",
    "CRIME = CRIME[CRIME.Y < 38]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.title('SF Crime Distribution')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.scatter(CRIME.X, CRIME.Y, s = 0.5, c = 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print the different categories\n",
    "print('Categories :',CRIME.Category.unique())\n",
    "\n",
    "CRIME.set_index('Category', inplace = True)\n",
    "# print the description of OTHER OFFENSES crimes \n",
    "print('Other offenses :',CRIME.loc['OTHER OFFENSES'].Descript.unique())\n",
    "\n",
    "# delete OTHER OFFENSES crimes\n",
    "CRIME.drop('OTHER OFFENSES', inplace=True)\n",
    "CRIME.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the different categories\n",
    "print('Categories :',CRIME.Category.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print the different categories\n",
    "print('Categories :',CRIME.Category.unique())\n",
    "\n",
    "CRIME.set_index('Category', inplace = True)\n",
    "# print the description of OTHER OFFENSES crimes \n",
    "print('Non criminal :',CRIME.loc['NON-CRIMINAL'].Descript.unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# delete Non-Criminal crimes\n",
    "CRIME.drop('NON-CRIMINAL', inplace=True)\n",
    "CRIME.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the different categories\n",
    "print('Categories :',CRIME.Category.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print the different categories\n",
    "print('Categories :',CRIME.Category.unique())\n",
    "\n",
    "CRIME.set_index('Category', inplace = True)\n",
    "# print the description of TREA crimes \n",
    "print('Trea :',CRIME.loc['TREA'].Descript.unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete TREA crimes\n",
    "CRIME.drop('TREA', inplace=True)\n",
    "CRIME.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the different categories\n",
    "print('Categories :',CRIME.Category.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot unique values of selected features\n",
    "pd.value_counts(CRIME['Category']).plot(kind=\"bar\", figsize = (20, 8))\n",
    "plt.show()\n",
    "print(CRIME['Category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset in features and target variable\n",
    "feature_cols = ['X', 'Y', 'PdDistrict', 'DayOfWeek']\n",
    "X = CRIME[feature_cols] # Features\n",
    "y = CRIME.Category # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "class MultiColumnLabelEncoder:\n",
    "    def __init__(self,columns = None):\n",
    "        self.columns = columns # array of column names to encode\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self # not relevant here\n",
    "\n",
    "    def transform(self,X):\n",
    "        '''\n",
    "        Transforms columns of X specified in self.columns using\n",
    "        LabelEncoder(). If no columns specified, transforms all\n",
    "        columns in X.\n",
    "        '''\n",
    "        output = X.copy()\n",
    "        if self.columns is not None:\n",
    "            for col in self.columns:\n",
    "                output[col] = LabelEncoder().fit_transform(output[col])\n",
    "        else:\n",
    "            for colname,col in output.iteritems():\n",
    "                output[colname] = LabelEncoder().fit_transform(col)\n",
    "        return output\n",
    "\n",
    "    def fit_transform(self,X,y=None):\n",
    "        return self.fit(X,y).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CRIME = MultiColumnLabelEncoder(columns = [\"PdDistrict\", \"DayOfWeek\", \"Category\", \"Location\"]).fit_transform(CRIME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features for following models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset in features and target variable\n",
    "feature_cols = ['X', 'Y', 'PdDistrict', 'Hour']\n",
    "X = CRIME[feature_cols] # Features\n",
    "y = CRIME.Category # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'min_samples_split':[50, 300, 500, 600] }\n",
    "\n",
    "treeclf = DecisionTreeClassifier(min_samples_split=300, \n",
    "                                 criterion='entropy', max_depth=4, \n",
    "                                 random_state=1)\n",
    "\n",
    "#treeclf = GridSearchCV(DecisionTreeClassifier(criterion='entropy', max_depth=6, \n",
    "#                                 random_state=1), param_grid)\n",
    "\n",
    "treeclf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# \"Gini importance\" of each feature: the total reduction of error brought by that feature\n",
    "pd.DataFrame({'feature':feature_cols, 'importance':treeclf.feature_importances_}).sort_values(['importance'], ascending=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred = treeclf.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import metrics\n",
    "metrics.mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'min_samples_split':[50, 300, 500, 600] }\n",
    "\n",
    "treeclf = DecisionTreeClassifier(min_samples_split=300, \n",
    "                                 criterion='gini', max_depth=4, \n",
    "                                 random_state=1)\n",
    "\n",
    "#treeclf = GridSearchCV(DecisionTreeClassifier(criterion='entropy', max_depth=6, \n",
    "#                                 random_state=1), param_grid)\n",
    "\n",
    "treeclf.fit(X_train, y_train)\n",
    "y_pred = treeclf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fit to data and predict using pipelined scaling, GNB and PCA.\n",
    "std_clf = make_pipeline(StandardScaler(), PCA(n_components=3), GaussianNB())\n",
    "std_clf.fit(X_train, y_train)\n",
    "pred_test_std = std_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show prediction accuracies in scaled and unscaled data.\n",
    "print('\\nPrediction accuracy for the standardized test dataset with PCA')\n",
    "print('{:.2%}\\n'.format(metrics.accuracy_score(y_test, pred_test_std)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=300)\n",
    "knn.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(criterion='gini',\n",
    "                             min_samples_split=500,\n",
    "                            n_estimators=10,\n",
    "                            n_jobs=2)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "y_pred = rfc.predict(X_test)\n",
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset in features and target variable\n",
    "feature_cols = ['Location', 'PdDistrict', 'DayOfWeek', 'Hour']\n",
    "X = CRIME[feature_cols] # Features\n",
    "y = CRIME.Category # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'min_samples_split':[50, 300, 500, 600] }\n",
    "\n",
    "treeclf = DecisionTreeClassifier(min_samples_split=300, \n",
    "                                 criterion='entropy', max_depth=4, \n",
    "                                 random_state=1)\n",
    "\n",
    "#treeclf = GridSearchCV(DecisionTreeClassifier(criterion='entropy', max_depth=6, \n",
    "#                                 random_state=1), param_grid)\n",
    "\n",
    "treeclf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = treeclf.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# \"Gini importance\" of each feature: the total reduction of error brought by that feature\n",
    "pd.DataFrame({'feature':feature_cols, 'importance':treeclf.feature_importances_}).sort_values(['importance'], ascending=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'min_samples_split':[50, 300, 500, 600] }\n",
    "\n",
    "treeclf = DecisionTreeClassifier(min_samples_split=300, \n",
    "                                 criterion='gini', max_depth=4, \n",
    "                                 random_state=1)\n",
    "\n",
    "#treeclf = GridSearchCV(DecisionTreeClassifier(criterion='entropy', max_depth=6, \n",
    "#                                 random_state=1), param_grid)\n",
    "\n",
    "treeclf.fit(X_train, y_train)\n",
    "y_pred = treeclf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset in features and target variable\n",
    "feature_cols = ['Location', 'X', 'Y', 'DayOfWeek', 'Hour']\n",
    "X = CRIME[feature_cols] # Features\n",
    "y = CRIME.Category # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'min_samples_split':[50, 300, 500, 600] }\n",
    "\n",
    "treeclf = DecisionTreeClassifier(min_samples_split=300, \n",
    "                                 criterion='entropy', max_depth=4, \n",
    "                                 random_state=1)\n",
    "\n",
    "#treeclf = GridSearchCV(DecisionTreeClassifier(criterion='entropy', max_depth=6, \n",
    "#                                 random_state=1), param_grid)\n",
    "\n",
    "treeclf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = treeclf.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# \"Gini importance\" of each feature: the total reduction of error brought by that feature\n",
    "pd.DataFrame({'feature':feature_cols, 'importance':treeclf.feature_importances_}).sort_values(['importance'], ascending=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit to data and predict using pipelined scaling, GNB and PCA.\n",
    "std_clf = make_pipeline(StandardScaler(), PCA(n_components=3), GaussianNB())\n",
    "std_clf.fit(X_train, y_train)\n",
    "pred_test_std = std_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show prediction accuracies in scaled and unscaled data.\n",
    "print('\\nPrediction accuracy for the standardized test dataset with PCA')\n",
    "print('{:.2%}\\n'.format(metrics.accuracy_score(y_test, pred_test_std)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset in features and target variable\n",
    "feature_cols = ['Location', 'Hour']\n",
    "X = CRIME[feature_cols] # Features\n",
    "y = CRIME.Category # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'min_samples_split':[50, 300, 500, 600] }\n",
    "\n",
    "treeclf = DecisionTreeClassifier(min_samples_split=300, \n",
    "                                 criterion='entropy', max_depth=4, \n",
    "                                 random_state=1)\n",
    "\n",
    "#treeclf = GridSearchCV(DecisionTreeClassifier(criterion='entropy', max_depth=6, \n",
    "#                                 random_state=1), param_grid)\n",
    "\n",
    "treeclf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = treeclf.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Gini importance\" of each feature: the total reduction of error brought by that feature\n",
    "pd.DataFrame({'feature':feature_cols, 'importance':treeclf.feature_importances_}).sort_values(['importance'], ascending=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit to data and predict using pipelined scaling, GNB and PCA.\n",
    "std_clf = make_pipeline(StandardScaler(), PCA(n_components=2), GaussianNB())\n",
    "std_clf.fit(X_train, y_train)\n",
    "pred_test_std = std_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show prediction accuracies in scaled and unscaled data.\n",
    "print('\\nPrediction accuracy for the standardized test dataset with PCA')\n",
    "print('{:.2%}\\n'.format(metrics.accuracy_score(y_test, pred_test_std)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=300)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset in features and target variable\n",
    "feature_cols = ['Location', 'X', 'Y', 'DayOfWeek', 'Hour']\n",
    "X = CRIME[feature_cols] # Features\n",
    "y = CRIME.Category # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Converting into dummy features for scikit-learn\n",
    "# X = pd.get_dummies(X, prefix='is_') \n",
    "# Fill Nan with 0\n",
    "X = X.fillna(0)\n",
    "# Gather column names\n",
    "feature_names = list(X)\n",
    "target_names = list(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data into training and testing datasets\n",
    "seed = 42\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import pydotplus\n",
    "from IPython.display import Image \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to be tested\n",
    "parameters = {'criterion':['gini', 'entropy'], 'max_depth':[None, 2, 3]}\n",
    "# Use grid search with 3 K-Fold to find the best parameters\n",
    "scoring = 'accuracy'\n",
    "kfold = model_selection.KFold(n_splits=3, random_state=seed)\n",
    "# Comparison\n",
    "dt = tree.DecisionTreeClassifier()\n",
    "clf = GridSearchCV(dt, parameters, cv=kfold, scoring=scoring)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Best estimator: \", clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with the best parameters\n",
    "dt = clf.best_estimator_\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = dt.feature_importances_\n",
    "std = np.std([importances],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "importance_to_plot = []\n",
    "for f in range(X.shape[1]):\n",
    "    if(importances[indices[f]]):\n",
    "        importance_to_plot.append(importances[indices[f]])\n",
    "        print(\"%d. feature %s (%f)\" % (f + 1, feature_names[f], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'importances' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-9de053edb5c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Feature importances\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m plt.bar(range(X.shape[1]), importances[indices],\n\u001b[0m\u001b[1;32m      5\u001b[0m        color=\"r\", yerr=std[indices], align=\"center\")\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'importances' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, len(importance_to_plot)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot and store the decision tree\n",
    "dot_data = tree.export_graphviz(dt, out_file=None, \n",
    "                         feature_names=feature_names,  \n",
    "                         class_names=target_names,  \n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True)  \n",
    "graph = pydotplus.graph_from_dot_data(dot_data) \n",
    "graph.write_pdf(\"DecisionTree.pdf\")\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-a61c66495f84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Group each category and then plot to show the number of each category\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcategories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DayOfWeek\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"DayOfWeek\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m categories.plot(kind='barh', title=\"Count of DayOfWeek\",\n\u001b[1;32m      5\u001b[0m                     \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame of the districts and crime counts per district\n",
    "CRIME.groupby(['Category', 'PdDistrict']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-86b6aaae30bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Display category count per district/Neighborhood\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPdDistrict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Count'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CENTRAL\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"NORTHERN\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"PARK\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"SOUTHERN\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MISSION\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TENDERLOIN\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"RICHMOND\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TARAVAL\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"INGLESIDE\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"BAYVIEW\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Display category count per district/Neighborhood\n",
    "a = df.PdDistrict.value_counts()\n",
    "result = pd.DataFrame(data=a.values, index=a.index, columns=['Count'])\n",
    "result = result.reindex([\"CENTRAL\", \"NORTHERN\", \"PARK\", \"SOUTHERN\", \"MISSION\", \"TENDERLOIN\", \"RICHMOND\", \"TARAVAL\", \"INGLESIDE\", \"BAYVIEW\"])\n",
    "result = result.reset_index()\n",
    "result.rename({'index': 'Neighborhood'}, axis='columns', inplace=True)\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sunday</th>\n",
       "      <th>Monday</th>\n",
       "      <th>Tuesday</th>\n",
       "      <th>Wednesday</th>\n",
       "      <th>Thursday</th>\n",
       "      <th>Friday</th>\n",
       "      <th>Saturday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15310</td>\n",
       "      <td>15572</td>\n",
       "      <td>15825</td>\n",
       "      <td>15821</td>\n",
       "      <td>16122</td>\n",
       "      <td>17514</td>\n",
       "      <td>16867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sunday  Monday  Tuesday  Wednesday  Thursday  Friday  Saturday\n",
       "0   15310   15572    15825      15821     16122   17514     16867"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DataFrame of the day of week and crime counts per day\n",
    "dow = ['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday']\n",
    "days_df = pd.DataFrame({dow[i]: [sum([dow[i] in x for x in CRIME['DayOfWeek']])] \n",
    "          for i in range(len(dow))})\n",
    "days_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
